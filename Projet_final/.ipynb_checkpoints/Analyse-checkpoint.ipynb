{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'idx2numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01midx2numpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_from_file\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprincipal_RBM_alpha\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'idx2numpy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from idx2numpy import convert_from_file\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from principal_RBM_alpha import *\n",
    "from principal_DBN_alpha import *\n",
    "from principal_DNN_MNIST import *\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Etude sur Binary AlphaDigit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cahrge les données\n",
    "data_path = \"data/\"\n",
    "alphadigs_path = data_path + \"binaryalphadigs.mat\"\n",
    "\n",
    "indices = [3]\n",
    "p, q = 320, 30\n",
    "nb_iter = 200\n",
    "alpha = 0.1\n",
    "batch_size = 10\n",
    "nb_iter_gibbs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lire_alpha_digit(alphadigs_path, indices) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBM\n",
    "#initialisation\n",
    "rbm = RBM(p, q)\n",
    "#train\n",
    "rbm, losses = train_RBM(rbm, X, nb_iter, batch_size, alpha)\n",
    "#Test\n",
    "imgs = generer_image_RBM(rbm, nb_iter_gibbs, 3, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "idx = [6, 33]\n",
    "data = lire_alpha_digit(alphadigs_path, idx)\n",
    "dim_inp = data.shape[1]\n",
    "dim_out = 200\n",
    "dim_hid_lst = [230, 350, 220]\n",
    "batch_size = 15\n",
    "n_iter = 50\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN(dim_inp, dim_out, dim_hid_lst)\n",
    "dnn_trained = pretrain_DNN(dnn, data, n_iter, batch_size, lr)\n",
    "images = generer_image_DBN(dnn_trained, n_imgs=4, n_iter=n_iter, indices=idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Etude sur MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Preprocessing des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_file = 'train-images.idx3-ubyte'\n",
    "mnist_train_label_file = 'train-labels.idx1-ubyte'\n",
    "mnist_test_file = 't10k-images.idx3-ubyte'\n",
    "mnist_test_label_file = 't10k-labels.idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MNIST_data():\n",
    "  # Lire les fichiers\n",
    "  X_train = convert_from_file(data_path + mnist_train_file)\n",
    "  y_train = convert_from_file(data_path + mnist_train_label_file)\n",
    "  X_test = convert_from_file(data_path + mnist_test_file)\n",
    "  y_test = convert_from_file(data_path + mnist_test_label_file)\n",
    "\n",
    "  # Pour chaque image on convertit la matrice correspondante en vecteur\n",
    "  X_train = np.array([img.flatten() for img in X_train])\n",
    "  X_test = np.array([img.flatten() for img in X_test])\n",
    "\n",
    "  # Binariser les images\n",
    "  X_train = 1 * (X_train > 127) \n",
    "  X_test = 1 * (X_test > 127) \n",
    "\n",
    "  # Formatter les labels\n",
    "  def encode_labels(y):\n",
    "\t# Pour chaque image le label est un entier\n",
    "\t# on le transforme en vecteur dont les éléments\n",
    "\t# valent 0 sauf celui à l'indice du label qui vaut 1\n",
    "    n = y.shape[0]\n",
    "    y_ = np.zeros((n, y.max() + 1)) \n",
    "    y_[np.arange(n), y] = 1\n",
    "    return y_\n",
    "\n",
    "  y_train = encode_labels(y_train)\n",
    "  y_test = encode_labels(y_test)\n",
    "\n",
    "  # On mélange les données\n",
    "  X_train, y_train = shuffle(X_train, y_train)\n",
    "  X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "  return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_MNIST_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_MNIST_data\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension de X_train :\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension de y_train :\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_MNIST_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_MNIST_data()\n",
    "\n",
    "print(\"Dimension de X_train :\", X_train.shape)\n",
    "print(\"Dimension de y_train :\", y_train.shape)\n",
    "print('-' * 50)\n",
    "print(\"Dimension de X_test :\", X_test.shape)\n",
    "print(\"Dimension de y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Définition d'une classe pour l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m            \u001b[38;5;66;03m# learning rate\u001b[39;00m\n\u001b[1;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m                \u001b[38;5;66;03m# batch size\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m in_dim \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]      \u001b[38;5;66;03m# taille d'une image\u001b[39;00m\n\u001b[1;32m      8\u001b[0m out_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m                   \u001b[38;5;66;03m# nbre de classes du MNIST dataset\u001b[39;00m\n\u001b[1;32m     10\u001b[0m N_total \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Paramètres\n",
    "n_iter_rbm = 50               # nbre d'itérations pour les RBM\n",
    "n_iter_backprop = 100          # dnn iterations\n",
    "learning_rate = 0.1            # learning rate\n",
    "batch_size = 32                # batch size\n",
    "\n",
    "in_dim = X_train.shape[1]      # taille d'une image\n",
    "out_dim = 10                   # nbre de classes du MNIST dataset\n",
    "\n",
    "N_total = X_train.shape[0]     # taille des données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSingleAnalysis\u001b[39;00m():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, N\u001b[38;5;241m=\u001b[39mN_total, hidden_dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m], n_iter_rbm\u001b[38;5;241m=\u001b[39mn_iter_rbm, n_iter_backprop\u001b[38;5;241m=\u001b[39mn_iter_backprop,\n\u001b[1;32m      4\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, out_dim\u001b[38;5;241m=\u001b[39mout_dim):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANALYSE DES RESEAUX POUR N = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m et les couches \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mSingleAnalysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSingleAnalysis\u001b[39;00m():\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, N\u001b[38;5;241m=\u001b[39m\u001b[43mN_total\u001b[49m, hidden_dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m], n_iter_rbm\u001b[38;5;241m=\u001b[39mn_iter_rbm, n_iter_backprop\u001b[38;5;241m=\u001b[39mn_iter_backprop,\n\u001b[1;32m      4\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, out_dim\u001b[38;5;241m=\u001b[39mout_dim):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANALYSE DES RESEAUX POUR N = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m et les couches \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N_total' is not defined"
     ]
    }
   ],
   "source": [
    "class SingleAnalysis():\n",
    "\n",
    "    def __init__(self, N=N_total, hidden_dims=[200, 200], n_iter_rbm=n_iter_rbm, n_iter_backprop=n_iter_backprop,\n",
    "        learning_rate=learning_rate, batch_size=batch_size, out_dim=out_dim):\n",
    "\n",
    "        print(f\"ANALYSE DES RESEAUX POUR N = {N} et les couches {hidden_dims}\")\n",
    "        print('-' * 100)\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.N = N                          # taille des données pour l'apprentissage\n",
    "        n = int(self.N / 5)                 # taille des données pour le pré-apprentissage\n",
    "\n",
    "        # Initialisation des données d'apprentissage\n",
    "        X_train_ = X_train[:self.N, :]\n",
    "        y_train_ = y_train[:self.N, :]\n",
    "\n",
    "        # Initialisation de deux réseaux identiques\n",
    "        self.pretrained_dnn = DNN(in_dim, out_dim, hidden_dims)\n",
    "        self.dnn = DNN(in_dim, out_dim, hidden_dims)\n",
    "\n",
    "        print(\"Pré-apprentissage du premier réseau\")\n",
    "        print('-' * 70)\n",
    "        self.pretrained_dnn = pretrain_DNN(dnn=self.pretrained_dnn, X=X_train_[:n], \n",
    "                                    nb_iter=n_iter_rbm,\n",
    "                                    batch_size=batch_size,\n",
    "                                    learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "        print(\"\\n Apprentissage du premier réseau\")\n",
    "        print('-' * 70)\n",
    "        self.pretrained_dnn, pretrained_losses = retropropagation(dnn=self.pretrained_dnn,\n",
    "                                                        X=X_train_, y=y_train_,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        n_iter=n_iter_backprop,\n",
    "                                                        learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "        print(\"\\n Apprentissage du deuxième réseau\")\n",
    "        print('-' * 70)\n",
    "        self.dnn, losses = retropropagation(dnn=self.dnn, X=X_train_, y=y_train_,\n",
    "                                    batch_size=batch_size,\n",
    "                                    n_iter=n_iter_backprop,\n",
    "                                    learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "        self.final_loss = losses[-1]\n",
    "        self.pre_final_loss = pretrained_losses[-1]\n",
    "\n",
    "        # Calcul du taux d'erreur sur les données d'apprentissage\n",
    "        self.pre_acc_train = test_DNN(dnn=self.pretrained_dnn, X=X_train, y=y_train)\n",
    "        self.acc_train = test_DNN(dnn=self.dnn, X=X_train, y=y_train)\n",
    "\n",
    "        # Calcul du taux d'erreur sur les données de test\n",
    "        self.pre_acc_test = test_DNN(dnn=self.pretrained_dnn, X=X_test, y=y_test)\n",
    "        self.acc_test = test_DNN(dnn=self.dnn, X=X_test, y=y_test)\n",
    "\n",
    "    def performance(self):\n",
    "        return self.pre_acc_train, self.acc_train, self.pre_acc_test, self.acc_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Exemple pour $N=1000$ et $hidden\\_dims=[200, 200]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_analysis = SingleAnalysis(N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient les performances suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Réseau pré-entraîné\")\n",
    "# print('-' * 30)\n",
    "# print(f\"Cross-entropy train : {ex_analysis.pre_final_loss:.4f}\")\n",
    "# print(f\"Train Accuracy : {(ex_analysis.pre_acc_train)*100 : .2f} %\")\n",
    "# print(f\"Test Accuracy : {(ex_analysis.pre_acc_test)*100 : .2f} % \\n\")\n",
    "\n",
    "# print(\"Réseau entraîné\")\n",
    "# print('-' * 30)\n",
    "# print(f\"Cross-entropy train : {ex_analysis.final_loss:.4f}\")\n",
    "# print(f\"Train Accuracy : {(ex_analysis.acc_train)*100 : .2f} %\")\n",
    "# print(f\"Test Accuracy : {(ex_analysis.acc_test)*100 : .2f} % \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleures performances pour le réseau pré-entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"Train Accuracy (pretrained)\",\n",
    "    \"Train Accuracy\",\n",
    "    \"Test Accuracy (pretrained)\",\n",
    "    \"Test Accuracy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Analyse de l'influence du nombre de couches cachées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisNLayers():\n",
    "\n",
    "    def __init__(self, n_layer_list):\n",
    "        self.n_layer_list = n_layer_list\n",
    "\n",
    "        # initialisation d'un dataframe pour les results\n",
    "        self.results = pd.DataFrame(\n",
    "            index = n_layer_list,\n",
    "            columns = columns\n",
    "        ).rename_axis(\"n_layers\")\n",
    "\n",
    "        # Pour chaque valeur dans la liste n_layer_list\n",
    "        for n_layer in n_layer_list:\n",
    "            hidden_dims = [200] * n_layer\n",
    "            analysis_ = SingleAnalysis(hidden_dims=hidden_dims)\n",
    "            performance_analysis = analysis_.performance()\n",
    "            self.results.loc[n_layer] = performance_analysis\n",
    "    \n",
    "    def plot_train_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy (pretrained)\",\n",
    "                    label=\"Train Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy\",\n",
    "                    label=\"Train Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données d'apprentissage en fonction du nombre de couche\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_test_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy (pretrained)\",\n",
    "                    label=\"Test Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy\",\n",
    "                    label=\"Test Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données de test en fonction du nombre de couche\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE DES RESEAUX POUR N = 60000 et les couches [200, 200]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pré-apprentissage du premier réseau\n",
      "----------------------------------------------------------------------\n",
      "Pré-entrainement de la couche (1/3) du DNN\n",
      "Iteration RBM (0/50) \t  MSE : 0.0330\n",
      "Pré-entrainement de la couche (2/3) du DNN\n",
      "Iteration RBM (0/50) \t  MSE : 0.0613\n",
      "Pré-entrainement de la couche (3/3) du DNN\n",
      "Iteration RBM (0/50) \t  MSE : 0.0925\n",
      "\n",
      " Apprentissage du premier réseau\n",
      "----------------------------------------------------------------------\n",
      "Iteration Rétropropagation (0/100) \t cross_entropy : 0.4433\n"
     ]
    }
   ],
   "source": [
    "analysis_n_layers = AnalysisNLayers(range(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_layers.plot_train_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_layers.plot_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Analyse de l'influence du nombre de neurones par couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisNUnits():\n",
    "\n",
    "    def __init__(self, n_units_list):\n",
    "        self.n_units_list = n_units_list\n",
    "\n",
    "        # initialisation d'un dataframe pour les results\n",
    "        self.results = pd.DataFrame(\n",
    "            index = n_units_list,\n",
    "            columns = columns\n",
    "        ).rename_axis(\"n_units\")\n",
    "\n",
    "        # Pour chaque valeur dans la liste n_units_list\n",
    "        for n_units in n_units_list:\n",
    "            hidden_dims = [n_units] * 2\n",
    "            analysis_ = SingleAnalysis(hidden_dims=hidden_dims)\n",
    "            performance_analysis = analysis_.performance()\n",
    "            self.results.loc[n_units] = performance_analysis\n",
    "    \n",
    "    def plot_train_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy (pretrained)\",\n",
    "                    label=\"Train Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy\",\n",
    "                    label=\"Train Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données d'apprentissage en fonction du nombre de neurones par couche\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_test_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy (pretrained)\",\n",
    "                    label=\"Test Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy\",\n",
    "                    label=\"Test Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données de test en fonction du nombre de neurones par couche\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE DES RESEAUX POUR N = 60000 et les couches [200, 200]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pré-apprentissage du premier réseau\n",
      "----------------------------------------------------------------------\n",
      "Pré-entrainement de la couche (1/3) du DNN\n",
      "Iteration RBM (0/100) \t  MSE : 0.0330\n"
     ]
    }
   ],
   "source": [
    "analysis_n_units = AnalysisNUnits(range(100, 800, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_units.plot_train_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_units.plot_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Analyse de l'influence de la taille des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisNTrain():\n",
    "\n",
    "    def __init__(self, n_train_list):\n",
    "        self.n_train_list = n_train_list\n",
    "\n",
    "        # initialisation d'un dataframe pour les results\n",
    "        self.results = pd.DataFrame(\n",
    "            index = n_train_list,\n",
    "            columns = columns\n",
    "        ).rename_axis(\"n_train\")\n",
    "\n",
    "        # Pour chaque valeur dans la liste n_train_list\n",
    "        for n_train in n_train_list:\n",
    "            analysis_ = SingleAnalysis(N=n_train)\n",
    "            performance_analysis = analysis_.performance()\n",
    "            self.results.loc[n_train] = performance_analysis\n",
    "    \n",
    "    def plot_train_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy (pretrained)\",\n",
    "                    label=\"Train Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Train Accuracy\",\n",
    "                    label=\"Train Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données d'apprentissage en fonction de leur taille\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_test_results(self):\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy (pretrained)\",\n",
    "                    label=\"Test Accuracy (pretrained)\"\n",
    "        )\n",
    "        sns.lineplot(data=self.results, x=self.results.index,\n",
    "                    y=\"Test Accuracy\",\n",
    "                    label=\"Test Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Taux d'erreur sur les données de test en fonction de la taille des données d'apprentissage\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SingleAnalysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m n_train_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m7000\u001b[39m, \u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m30000\u001b[39m, \u001b[38;5;241m60000\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m analysis_n_train \u001b[38;5;241m=\u001b[39m \u001b[43mAnalysisNTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_train_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mAnalysisNTrain.__init__\u001b[0;34m(self, n_train_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Pour chaque valeur dans la liste n_train_list\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_train \u001b[38;5;129;01min\u001b[39;00m n_train_list:\n\u001b[0;32m---> 14\u001b[0m     analysis_ \u001b[38;5;241m=\u001b[39m \u001b[43mSingleAnalysis\u001b[49m(N\u001b[38;5;241m=\u001b[39mn_train)\n\u001b[1;32m     15\u001b[0m     performance_analysis \u001b[38;5;241m=\u001b[39m analysis_\u001b[38;5;241m.\u001b[39mperformance()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mloc[n_train] \u001b[38;5;241m=\u001b[39m performance_analysis\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SingleAnalysis' is not defined"
     ]
    }
   ],
   "source": [
    "n_train_list = [1000, 3000, 7000, 10000, 30000, 60000]\n",
    "analysis_n_train = AnalysisNTrain(n_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_train.plot_train_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n_train.plot_test_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
